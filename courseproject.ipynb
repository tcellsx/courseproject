{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df8f3456-cbe3-4749-9371-793177d3c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n",
      "Graph created with 94861 nodes and 154719 edges.\n",
      "Calculating centrality...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 133\u001b[0m\n\u001b[1;32m    131\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwitter-small.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Make sure this points to your file\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating graph...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m graph_with_centrality \u001b[38;5;241m=\u001b[39m create_mention_graph_with_centrality(filepath)\n",
      "Cell \u001b[0;32mIn[35], line 111\u001b[0m, in \u001b[0;36mcreate_mention_graph_with_centrality\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_edges()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating centrality...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m neighborhood_lower_bound(G)\n\u001b[1;32m    112\u001b[0m nx\u001b[38;5;241m.\u001b[39mset_node_attributes(G, lower_bounds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_centrality\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    114\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m, in \u001b[0;36mneighborhood_lower_bound\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     21\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# CORRECTED: Precompute reachability information ONCE *BEFORE* the main loop\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m reachable_nodes_dict \u001b[38;5;241m=\u001b[39m {node: reachable_nodes(graph, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes}\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# CORRECTED: Precompute reachability information ONCE *BEFORE* the main loop\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m reachable_nodes_dict \u001b[38;5;241m=\u001b[39m {node: reachable_nodes(graph, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes}\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m, in \u001b[0;36mreachable_nodes\u001b[0;34m(graph, start_node)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Efficiently counts reachable nodes in an undirected graph.\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(nx\u001b[38;5;241m.\u001b[39mnode_connected_component(graph, start_node)))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXError:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 8:4\u001b[0m, in \u001b[0;36margmap_node_connected_component_5\u001b[0;34m(G, n, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/site-packages/networkx/algorithms/components/connected.py:189\u001b[0m, in \u001b[0;36mnode_connected_component\u001b[0;34m(G, n)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;129m@not_implemented_for\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@nx\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnode_connected_component\u001b[39m(G, n):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the set of nodes in the component of graph containing node n.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _plain_bfs(G, n)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/site-packages/networkx/algorithms/components/connected.py:204\u001b[0m, in \u001b[0;36m_plain_bfs\u001b[0;34m(G, source)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m adj[v]:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n\u001b[0;32m--> 204\u001b[0m         seen\u001b[38;5;241m.\u001b[39madd(w)\n\u001b[1;32m    205\u001b[0m         nextlevel\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seen) \u001b[38;5;241m==\u001b[39m n:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import itertools\n",
    "#import cProfile\n",
    "#cProfile.run('create_mention_graph_with_centrality(\"twitter-small.tsv\")')\n",
    "\n",
    "def reachable_nodes(graph, start_node):\n",
    "    \"\"\"Efficiently counts reachable nodes in an undirected graph.\"\"\"\n",
    "    try:\n",
    "        return len(list(nx.node_connected_component(graph, start_node)))\n",
    "    except nx.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "def neighborhood_lower_bound(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    lower_bounds = {}\n",
    "\n",
    "    # CORRECTED: Precompute reachability information ONCE *BEFORE* the main loop\n",
    "    reachable_nodes_dict = {node: reachable_nodes(graph, node) for node in nodes}\n",
    "    print('1')\n",
    "\n",
    "    k = 2\n",
    "    max_iterations = 10  # Limit iterations to prevent excessive runtime.\n",
    "\n",
    "    while k <= max_iterations:\n",
    "        Y = {}\n",
    "        S_un = {}\n",
    "        nVisited = {}\n",
    "        finished = {}\n",
    "\n",
    "        # Initialization - use degrees for efficiency\n",
    "        for s in nodes:\n",
    "            degree_s = graph.degree(s)\n",
    "            Y[(k - 1, s)] = degree_s\n",
    "            S_un[(k - 1, s)] = degree_s\n",
    "            nVisited[s] = degree_s + 1\n",
    "            finished[s] = False\n",
    "\n",
    "        nFinished = 0\n",
    "        while nFinished < n:\n",
    "            for s in nodes:\n",
    "                if finished[s]:\n",
    "                    continue\n",
    "                r_v = reachable_nodes_dict[s]\n",
    "                print('2')\n",
    "\n",
    "                if k == 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in graph.neighbors(s)) - graph.degree(s)\n",
    "                elif k > 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in graph.neighbors(s)) - Y.get((k - 2, s), 0) * (\n",
    "                                graph.degree(s) - 1)\n",
    "                else:\n",
    "                    Y[(k, s)] = 0  # Should not happen\n",
    "\n",
    "                nVisited[s] += Y.get((k - 1, s), 0)\n",
    "\n",
    "                if nVisited[s] < r_v:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * Y.get((k - 1, s), 0)\n",
    "                else:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * (r_v - (nVisited[s] - Y.get((k - 1, s), 0)))\n",
    "                    nFinished += 1\n",
    "                    finished[s] = True\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    for v in nodes:\n",
    "        r_v = reachable_nodes_dict[v]\n",
    "        lower_bounds[v] = (n - 1) * S_un.get((k - 1, v), 0) / ((r_v - 1) ** 2) if r_v > 1 else 0\n",
    "\n",
    "    return lower_bounds\n",
    "\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath):\n",
    "    start_time = time.time()\n",
    "    edge_weights = defaultdict(int)\n",
    "\n",
    "    def process_chunk(chunk):\n",
    "        for row in chunk:\n",
    "            try:\n",
    "                timestamp, user, tweet_text = row\n",
    "                mentions = re.findall(r'@([a-zA-Z0-9_]+)', tweet_text)\n",
    "                for mention in mentions:\n",
    "                    edge_weights[(user, mention)] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Error processing row: {row}. Skipping. Error: {e}\")\n",
    "\n",
    "    chunk_size = 100000\n",
    "    current_chunk = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            current_chunk.append(row)\n",
    "            if len(current_chunk) == chunk_size:\n",
    "                process_chunk(current_chunk)\n",
    "                current_chunk = []\n",
    "\n",
    "    if current_chunk:\n",
    "        process_chunk(current_chunk)\n",
    "\n",
    "    G = nx.Graph()  # Create an undirected graph directly\n",
    "    for (u, v), weight in edge_weights.items():\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "\n",
    "    print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    print(\"Calculating centrality...\")\n",
    "    lower_bounds = neighborhood_lower_bound(G)\n",
    "    nx.set_node_attributes(G, lower_bounds, 'lower_centrality')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "\n",
    "    sorted_centralities = sorted(\n",
    "        nx.get_node_attributes(G, 'lower_centrality').items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    print(\"\\nTop 10 nodes by lower centrality bound:\")\n",
    "    for node, centrality in sorted_centralities[:10]:\n",
    "        print(f\"Node: {node}, Lower Centrality: {centrality}\")\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"twitter-small.tsv\"  # Make sure this points to your file\n",
    "    print(\"Creating graph...\")\n",
    "    graph_with_centrality = create_mention_graph_with_centrality(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2b7d4e-0eb0-4be3-a712-5953df643c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n",
      "Graph created with 94861 nodes and 155574 edges.\n",
      "Calculating closeness centrality...\n",
      "接近中心性最高的10个节点：['tamaraschilling', 'americandream09', 'nachhi', 'teddy_salad', 'drjennifer', 'medic_ray', 'pcpitcrew', 'judismile', 'kellythomas1', 'june_prissydog']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def memory_efficient_lin_closeness(G):\n",
    "    \"\"\"计算图中所有节点的Lin接近中心性，使用内存效率更高的方法。\"\"\"\n",
    "    n = G.number_of_nodes()\n",
    "    lin_centrality = {}\n",
    "    for node in G.nodes():\n",
    "        length = nx.single_source_shortest_path_length(G, node)\n",
    "        reachable = len(length)\n",
    "        total_distance = sum(length.values())\n",
    "        if reachable > 1:\n",
    "            lin_centrality[node] = (reachable - 1)**2 / ((n - 1) * total_distance)\n",
    "        else:\n",
    "            lin_centrality[node] = 0.0\n",
    "    return lin_centrality\n",
    "\n",
    "def top_k_closeness_centrality_nodes(G, k):\n",
    "    \"\"\"根据Lin接近中心性查找前k个节点。\"\"\"\n",
    "    closeness_centrality = memory_efficient_lin_closeness(G)\n",
    "    sorted_nodes = sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "    return [node for node, centrality_value in sorted_nodes[:k]]\n",
    "\n",
    "def create_mention_graph(filepath):\n",
    "    edge_weights = defaultdict(int)\n",
    "    \n",
    "    def process_chunk(chunk):\n",
    "        for row in chunk:\n",
    "            try:\n",
    "                timestamp, user, tweet_text = row\n",
    "                mentions = re.findall(r'@([a-zA-Z0-9_]+)', tweet_text)\n",
    "                for mention in mentions:\n",
    "                    edge_weights[(user, mention)] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Error processing row: {row}. Skipping. Error: {e}\")\n",
    "    \n",
    "    chunk_size = 100000  # 增大块大小以减少 I/O 操作\n",
    "    current_chunk = []\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            current_chunk.append(row)\n",
    "            if len(current_chunk) == chunk_size:\n",
    "                process_chunk(current_chunk)\n",
    "                current_chunk = []\n",
    "    \n",
    "    if current_chunk:\n",
    "        process_chunk(current_chunk)\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    for (u, v), weight in edge_weights.items():\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "    \n",
    "    print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    return G\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"twitter-small.tsv\"\n",
    "    print(\"Creating graph...\")\n",
    "    graph = create_mention_graph(filepath)\n",
    "    k = 10\n",
    "\n",
    "    if graph.number_of_nodes() == 0:\n",
    "        print(\"The graph is empty. Please check your input file.\")\n",
    "    else:\n",
    "        print(\"Calculating closeness centrality...\")\n",
    "        top_k_nodes = top_k_closeness_centrality_nodes(graph, k)\n",
    "        print(f\"接近中心性最高的{k}个节点：{top_k_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e081d-ec00-4a23-8f16-828123ed9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('create_mention_graph_with_centrality(\"twitter-small.tsv\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a8f14-3a28-4996-b1c0-e04253217430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fe96cb-5e8f-43d7-b25d-c2c262219446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n",
      "Graph created with 94861 nodes and 154719 edges.\n",
      "Calculating centrality...\n",
      "         5205774151 function calls (5205774150 primitive calls) in 862.869 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "1680866949/1680866948  144.511    0.000  144.511    0.000 1310056601.py:21(<genexpr>)\n",
      "        1    0.080    0.080  862.868  862.868 1310056601.py:24(neighborhood_lower_bound)\n",
      "        1    0.001    0.001  862.470  862.470 1310056601.py:28(<dictcomp>)\n",
      "        1    0.000    0.000  862.868  862.868 1310056601.py:83(create_mention_graph_with_centrality)\n",
      "        1    0.036    0.036    0.068    0.068 1310056601.py:87(process_chunk)\n",
      "     8212  405.942    0.049 1719.657    0.209 1310056601.py:9(reachable_nodes_bfs)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      711    0.000    0.000    0.002    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.000    0.000  862.869  862.869 <string>:1(<module>)\n",
      "    39940    0.007    0.000    0.032    0.000 __init__.py:208(findall)\n",
      "    39940    0.006    0.000    0.009    0.000 __init__.py:272(_compile)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:981(__get__)\n",
      "614340980  121.417    0.000  140.519    0.000 graph.py:1315(neighbors)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:1481(degree)\n",
      "        1    0.000    0.000    0.029    0.029 graph.py:1869(size)\n",
      "    94862    0.008    0.000    0.026    0.000 graph.py:1905(<genexpr>)\n",
      "        1    0.000    0.000    0.029    0.029 graph.py:1912(number_of_edges)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:332(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:37(__set__)\n",
      "     8212    0.007    0.000    0.007    0.000 graph.py:453(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:59(__set__)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:732(nodes)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:825(number_of_nodes)\n",
      "   155574    0.201    0.000    0.216    0.000 graph.py:893(add_edge)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:315(_modified_open)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:137(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:258(schedule)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:519(_is_master_process)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:546(_schedule_flush)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:624(write)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:178(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:182(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:185(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:205(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:417(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:424(__call__)\n",
      "    94862    0.016    0.000    0.018    0.000 reportviews.py:527(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "      711    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _csv.reader}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "    39944    0.003    0.000    0.003    0.000 {built-in method builtins.isinstance}\n",
      "614340981   19.102    0.000   19.102    0.000 {built-in method builtins.iter}\n",
      "   143019    0.006    0.000    0.006    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.003    0.003    0.029    0.029 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "614340980   28.447    0.000   28.447    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    39940    0.002    0.000    0.002    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "614340980  112.090    0.000  256.602    0.000 {method 'extend' of 'collections.deque' objects}\n",
      "    39940    0.016    0.000    0.016    0.000 {method 'findall' of 're.Pattern' objects}\n",
      "   155578    0.006    0.000    0.006    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "1066526192   30.952    0.000   30.952    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "   155575    0.008    0.000    0.008    0.000 {method 'update' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwitter-small.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Make sure this points to your file\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating graph...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m cProfile\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_mention_graph_with_centrality(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwitter-small.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/cProfile.py:17\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(statement, filename, sort)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(statement, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pyprofile\u001b[38;5;241m.\u001b[39m_Utils(Profile)\u001b[38;5;241m.\u001b[39mrun(statement, filename, sort)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/profile.py:54\u001b[0m, in \u001b[0;36m_Utils.run\u001b[0;34m(self, statement, filename, sort)\u001b[0m\n\u001b[1;32m     52\u001b[0m prof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     prof\u001b[38;5;241m.\u001b[39mrun(statement)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/cProfile.py:96\u001b[0m, in \u001b[0;36mProfile.run\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m __main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunctx(cmd, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/first_learning/lib/python3.11/cProfile.py:101\u001b[0m, in \u001b[0;36mProfile.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     exec(cmd, \u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m, in \u001b[0;36mcreate_mention_graph_with_centrality\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_edges()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating centrality...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m neighborhood_lower_bound(G)\n\u001b[1;32m    117\u001b[0m nx\u001b[38;5;241m.\u001b[39mset_node_attributes(G, lower_bounds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_centrality\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mneighborhood_lower_bound\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     26\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes)\n\u001b[1;32m     27\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 28\u001b[0m reachable_nodes_dict \u001b[38;5;241m=\u001b[39m {node: reachable_nodes_bfs(graph, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes}\n\u001b[1;32m     30\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     31\u001b[0m max_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes)\n\u001b[1;32m     27\u001b[0m lower_bounds \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 28\u001b[0m reachable_nodes_dict \u001b[38;5;241m=\u001b[39m {node: reachable_nodes_bfs(graph, node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes}\n\u001b[1;32m     30\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     31\u001b[0m max_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mreachable_nodes_bfs\u001b[0;34m(graph, start_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m         visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m     20\u001b[0m         neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(graph\u001b[38;5;241m.\u001b[39mneighbors(node))\n\u001b[0;32m---> 21\u001b[0m         queue\u001b[38;5;241m.\u001b[39mextend(neighbor \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m neighbor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(visited)\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m         visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m     20\u001b[0m         neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(graph\u001b[38;5;241m.\u001b[39mneighbors(node))\n\u001b[0;32m---> 21\u001b[0m         queue\u001b[38;5;241m.\u001b[39mextend(neighbor \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m neighbors \u001b[38;5;28;01mif\u001b[39;00m neighbor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(visited)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import itertools\n",
    "\n",
    "def reachable_nodes_bfs(graph, start_node):\n",
    "    \"\"\"使用 deque 作为队列的高效 BFS 实现。\"\"\"\n",
    "    if start_node not in graph:\n",
    "        return 0\n",
    "\n",
    "    visited = set()\n",
    "    queue = deque([start_node])  # 使用 deque 作为队列\n",
    "    while queue:\n",
    "        node = queue.popleft()  # 使用 popleft() 高效地弹出队列元素\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "            queue.extend(neighbor for neighbor in neighbors if neighbor not in visited)\n",
    "    return len(visited)\n",
    "\n",
    "def neighborhood_lower_bound(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    lower_bounds = {}\n",
    "    reachable_nodes_dict = {node: reachable_nodes_bfs(graph, node) for node in nodes}\n",
    "\n",
    "    k = 2\n",
    "    max_iterations = 10\n",
    "    print('2')\n",
    "\n",
    "    # 预先计算所有节点的邻居\n",
    "    neighbors_dict = {node: list(graph.neighbors(node)) for node in nodes}\n",
    "    print('3')\n",
    "\n",
    "    while k <= max_iterations:\n",
    "        Y = {}\n",
    "        S_un = {}\n",
    "        nVisited = {}\n",
    "        finished = {}\n",
    "\n",
    "        for s in nodes:\n",
    "            degree_s = graph.degree(s)\n",
    "            Y[(k - 1, s)] = degree_s\n",
    "            S_un[(k - 1, s)] = degree_s\n",
    "            nVisited[s] = degree_s + 1\n",
    "            finished[s] = False\n",
    "\n",
    "        nFinished = 0\n",
    "        while nFinished < n:\n",
    "            for s in nodes:\n",
    "                if finished[s]:\n",
    "                    continue\n",
    "                r_v = reachable_nodes_dict[s]\n",
    "\n",
    "                if k == 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in neighbors_dict[s]) - graph.degree(s) # 使用预先计算的邻居\n",
    "                elif k > 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in neighbors_dict[s]) - Y.get((k - 2, s), 0) * (\n",
    "                                graph.degree(s) - 1)\n",
    "                else:\n",
    "                    Y[(k, s)] = 0\n",
    "\n",
    "                nVisited[s] += Y.get((k - 1, s), 0)\n",
    "\n",
    "                if nVisited[s] < r_v:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * Y.get((k - 1, s), 0)\n",
    "                else:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * (r_v - (nVisited[s] - Y.get((k - 1, s), 0)))\n",
    "                    nFinished += 1\n",
    "                    finished[s] = True\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    for v in nodes:\n",
    "        r_v = reachable_nodes_dict[v]\n",
    "        lower_bounds[v] = (n - 1) * S_un.get((k - 1, v), 0) / ((r_v - 1) ** 2) if r_v > 1 else 0\n",
    "\n",
    "    return lower_bounds\n",
    "\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath):\n",
    "    start_time = time.time()\n",
    "    edge_weights = defaultdict(int)\n",
    "\n",
    "    def process_chunk(chunk):\n",
    "        for row in chunk:\n",
    "            try:\n",
    "                timestamp, user, tweet_text = row\n",
    "                mentions = re.findall(r'@([a-zA-Z0-9_]+)', tweet_text)\n",
    "                for mention in mentions:\n",
    "                    edge_weights[(user, mention)] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Error processing row: {row}. Skipping. Error: {e}\")\n",
    "\n",
    "    chunk_size = 100000\n",
    "    current_chunk = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            current_chunk.append(row)\n",
    "            if len(current_chunk) == chunk_size:\n",
    "                process_chunk(current_chunk)\n",
    "                current_chunk = []\n",
    "\n",
    "    if current_chunk:\n",
    "        process_chunk(current_chunk)\n",
    "\n",
    "    G = nx.Graph()  # Create an undirected graph directly\n",
    "    for (u, v), weight in edge_weights.items():\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "\n",
    "    print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    print(\"Calculating centrality...\")\n",
    "    lower_bounds = neighborhood_lower_bound(G)\n",
    "    nx.set_node_attributes(G, lower_bounds, 'lower_centrality')\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "\n",
    "    sorted_centralities = sorted(\n",
    "        nx.get_node_attributes(G, 'lower_centrality').items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    print(\"\\nTop 10 nodes by lower centrality bound:\")\n",
    "    for node, centrality in sorted_centralities[:10]:\n",
    "        print(f\"Node: {node}, Lower Centrality: {centrality}\")\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"twitter-small.tsv\"  # Make sure this points to your file\n",
    "    print(\"Creating graph...\")\n",
    "    cProfile.run('create_mention_graph_with_centrality(\"twitter-small.tsv\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86b2dd-b5ad-45c5-bf05-205eea7f57b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e5018-99a2-4099-95f8-8de996a15aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
