{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536e023-25f4-4db7-b2a5-79f29db6f9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae778c-70b7-47c2-9413-95d0c3dde690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def neighborhood_lower_bound(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    lower_bounds = {}\n",
    "\n",
    "    k = 2\n",
    "    max_iterations = 100000  # 设置最大迭代次数\n",
    "\n",
    "    Y = {}\n",
    "    S_un = {}\n",
    "    nVisited = {}\n",
    "    finished = {}\n",
    "\n",
    "    for s in nodes:\n",
    "        degree_s = graph.degree(s)\n",
    "        Y[(1, s)] = degree_s\n",
    "        S_un[s] = degree_s\n",
    "        nVisited[s] = degree_s + 1\n",
    "        finished[s] = False\n",
    "\n",
    "    nFinished = 0\n",
    "\n",
    "    while nFinished < n and k <= max_iterations:\n",
    "        for s in nodes:\n",
    "            if finished[s]:\n",
    "                continue\n",
    "            if k == 2:\n",
    "                Y[(k, s)] = sum(Y.get((k-1, w), 0) for w in graph.neighbors(s)) - graph.degree(s)\n",
    "            else:\n",
    "                Y[(k, s)] = sum(Y.get((k-1, w), 0) for w in graph.neighbors(s)) - Y.get((k-2, s), 0) * (graph.degree(s) - 1)\n",
    "        \n",
    "        for s in nodes:\n",
    "            if finished[s]:\n",
    "                continue\n",
    "            y_k_minus_2 = Y.get((k-2, s), 0)\n",
    "            y_k_minus_1 = Y.get((k-1, s), 0)\n",
    "            nVisited[s] += y_k_minus_1\n",
    "            \n",
    "            if nVisited[s] < n:\n",
    "                S_un[s] += k * y_k_minus_1\n",
    "            else:\n",
    "                S_un[s] += k *(n-(nVisited[s] - y_k_minus_1))\n",
    "                nFinished += 1\n",
    "                finished[s] = True\n",
    "            Y[(k-2, s)] = y_k_minus_1\n",
    "            Y[(k-1, s)] = Y[(k, s)]\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    for v in nodes:\n",
    "        lower_bounds[v] = S_un[v] / (n - 1)\n",
    "\n",
    "    return lower_bounds\n",
    "\n",
    "def updateBoundsBFSCut(v, graph, x):\n",
    "    \"\"\"\n",
    "    计算将顶点 v 分隔开的割集大小的下界。\n",
    "\n",
    "    参数：\n",
    "        v: 起始顶点。\n",
    "        graph: networkx DiGraph。节点必须具有 'r' 属性。\n",
    "        Farn: 存储下界的字典（必须初始化）。\n",
    "        Top: top k 节点的列表（必须初始化）。\n",
    "        x: 一个阈值。\n",
    "\n",
    "    返回：\n",
    "        如果割集值超过 x，则返回 +∞；否则返回计算出的割集值，或者如果无变化则返回当前 Farn[v]。\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    Q = [(0,v)] #优先级队列，用于跟踪 BFS 的 (距离, 节点)\n",
    "    heapq.heapify(Q)\n",
    "    visited = {v}\n",
    "    d = 0\n",
    "    S = 0\n",
    "    y = graph.degree(v) - 1\n",
    "    nd = 1\n",
    "\n",
    "    while Q:\n",
    "        dist, u = heapq.heappop(Q)\n",
    "        if dist > d:\n",
    "            d += 1\n",
    "            #LCUT 计算\n",
    "            \n",
    "            LCUT = ((d+2)*(n-nd) + S - y )/(n-1)\n",
    "        \n",
    "\n",
    "            if LCUT >= x:\n",
    "                return float('inf')\n",
    "            y = 0  # 重置 y\n",
    "\n",
    "        for w in graph.neighbors(u):\n",
    "            if w not in visited:\n",
    "                visited.add(w)\n",
    "                dist_vw = nx.shortest_path_length(graph,v,w) #假设存在最短路径\n",
    "                heapq.heappush(Q,(dist_vw,w))\n",
    "                S += dist_vw  # 距离 d(v,w)\n",
    "                y += graph.degree(w)\n",
    "                nd += 1\n",
    "            else:\n",
    "                LCUT = LCUT + 1/(n-1)\n",
    "\n",
    "    #最终计算\n",
    "    LCUT_final = S / (n-1)\n",
    "\n",
    "    \n",
    "    return LCUT_final\n",
    "\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath, top_k=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_edges_from(data.values.tolist())\n",
    "    graph = directed_graph.to_undirected()\n",
    "\n",
    "    print(f\"Undirected graph created with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n",
    "    print(\"Calculating initial lower bounds...\")\n",
    "\n",
    "    initial_lower_bounds = neighborhood_lower_bound(graph)\n",
    "    \n",
    "    k_lowest_farness = heapq.nsmallest(top_k, initial_lower_bounds.items(), key=lambda item: item[1])\n",
    "    print(f\"\\n{top_k} nodes with lowest farness values:\")\n",
    "    for node, farness in k_lowest_farness:\n",
    "        print(f\"Node: {node}, Farness: {farness}\")\n",
    "    \n",
    "    Farn = initial_lower_bounds.copy()\n",
    "    Top = []\n",
    "    Q = [(Farn[node], node) for node in graph.nodes()]\n",
    "    heapq.heapify(Q)\n",
    "\n",
    "    initial_threshold = float('inf')\n",
    "\n",
    "\n",
    "    _, v = heapq.heappop(Q)\n",
    "    \n",
    "    print(f\"Processing node {v}\")\n",
    "\n",
    "    threshold = initial_threshold if len(Top) < top_k else Farn[Top[-1]]\n",
    "    refined_bound = updateBoundsBFSCut(v, graph, threshold)\n",
    "    \n",
    "    print(f\"Refined bound for node {v}: {refined_bound}\")\n",
    "\n",
    "    Farn[v] = refined_bound\n",
    "\n",
    "    while Q:\n",
    "        \n",
    "        if len(Top) < top_k:\n",
    "            Top.append(v)\n",
    "            Top.sort(key=lambda node: Farn[node])\n",
    "            print(f\"Added node {v} to Top. Current Top: {Top}\")\n",
    "        elif refined_bound < Farn[Top[-1]]:\n",
    "            Top.append(v)\n",
    "            Top.sort(key=lambda node: Farn[node])\n",
    "            Top = Top[:top_k]  # 保持Top的长度为top_k\n",
    "            print(f\"Added node {v} to Top and trimmed. Current Top: {Top}\")\n",
    "        else:\n",
    "            print(f\"Node {v} not added to Top as its bound is not better than current top\")\n",
    "\n",
    "        _, v = heapq.heappop(Q)\n",
    "    \n",
    "        print(f\"Processing node {v}\")\n",
    "\n",
    "        threshold = initial_threshold if len(Top) < top_k else Farn[Top[-1]]\n",
    "        refined_bound = updateBoundsBFSCut(v, graph, threshold)\n",
    "    \n",
    "        print(f\"Refined bound for node {v}: {refined_bound}\")\n",
    "\n",
    "        Farn[v] = refined_bound\n",
    "        \n",
    "        if len(Top) == top_k and Farn[v] >= Farn[Top[-1]]:\n",
    "            print(Farn[Q[0][1]])\n",
    "            print(Farn[Top[-1]])\n",
    "            print(\"Remaining nodes in Q cannot improve Top. Stopping.\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nFinal Top 10 nodes by refined lower centrality bound:\")\n",
    "    for i, node in enumerate(Top, 1):\n",
    "        print(f\"{i}. Node: {node}, Refined Lower Centrality: {Farn[node]:.10f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"com-youtube.ungraph.tsv\"  # 替换为你文件的路径\n",
    "    print(\"Creating graph...\")\n",
    "    graph_with_centrality = create_mention_graph_with_centrality(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283ddf7-8469-401b-a31b-9c92608205c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccee47-81f3-462c-b774-9e4f1d70d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_closeness_centrality(graph, top_k=10):\n",
    "    \"\"\"\n",
    "    计算图中节点的接近中心性,并返回 top k 个最高中心性的节点。\n",
    "\n",
    "    参数:\n",
    "    graph (networkx.Graph): 输入图\n",
    "    top_k (int): 返回前 k 个最高中心性的节点\n",
    "\n",
    "    返回:\n",
    "    dict: 包含 top k 个节点及其接近中心性值的字典\n",
    "    \"\"\"\n",
    "    # 计算每个节点的接近中心性\n",
    "    closeness_centrality = nx.closeness_centrality(graph)\n",
    "\n",
    "    # 获取 top k 个最高中心性的节点\n",
    "    top_nodes = heapq.nlargest(top_k, closeness_centrality, key=closeness_centrality.get)\n",
    "    top_centrality = {node: closeness_centrality[node] for node in top_nodes}\n",
    "\n",
    "    return top_centrality\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath, top_k=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_edges_from(data.values.tolist())\n",
    "    graph = directed_graph.to_undirected()\n",
    "\n",
    "    print(f\"Undirected graph created with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n",
    "\n",
    "    print(\"Calculating top k nodes by closeness centrality...\")\n",
    "    top_closeness = calculate_closeness_centrality(graph, top_k)\n",
    "\n",
    "    print(\"\\nTop 10 nodes by closeness centrality:\")\n",
    "    for i, (node, centrality) in enumerate(top_closeness.items(), 1):\n",
    "        print(f\"{i}. Node: {node}, Closeness Centrality: {centrality:.10f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"com-youtube.ungraph.tsv\"  # 替换为你文件的路径\n",
    "    print(\"Creating graph...\")\n",
    "    graph_with_centrality = create_mention_graph_with_centrality(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17afa0-8eeb-4702-b305-badd4feed28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04cf54-6bf7-4f09-a68b-ea6261a4d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def pagerank_lower_bound(graph):\n",
    "    # 计算每个节点的 PageRank 值\n",
    "    page_ranks = nx.pagerank(graph)\n",
    "    \n",
    "    # 将 PageRank 值的倒数作为下界\n",
    "    lower_bounds = {node: 1 / page_ranks[node] for node in graph.nodes()}\n",
    "    \n",
    "    return lower_bounds\n",
    "\n",
    "def updateBoundsBFSCut(v, graph, x):\n",
    "    \"\"\"\n",
    "    计算将顶点 v 分隔开的割集大小的下界。\n",
    "\n",
    "    参数：\n",
    "        v: 起始顶点。\n",
    "        graph: networkx DiGraph。节点必须具有 'r' 属性。\n",
    "        Farn: 存储下界的字典（必须初始化）。\n",
    "        Top: top k 节点的列表（必须初始化）。\n",
    "        x: 一个阈值。\n",
    "\n",
    "    返回：\n",
    "        如果割集值超过 x，则返回 +∞；否则返回计算出的割集值，或者如果无变化则返回当前 Farn[v]。\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    Q = [(0,v)] #优先级队列，用于跟踪 BFS 的 (距离, 节点)\n",
    "    heapq.heapify(Q)\n",
    "    visited = {v}\n",
    "    d = 0\n",
    "    S = 0\n",
    "    y = graph.degree(v) - 1\n",
    "    nd = 1\n",
    "\n",
    "    while Q:\n",
    "        dist, u = heapq.heappop(Q)\n",
    "        if dist > d:\n",
    "            d += 1\n",
    "            #LCUT 计算\n",
    "            \n",
    "            LCUT = ((d+2)*(n-nd) + S - y )/(n-1)\n",
    "        \n",
    "\n",
    "            if LCUT >= x:\n",
    "                return float('inf')\n",
    "            y = 0  # 重置 y\n",
    "\n",
    "        for w in graph.neighbors(u):\n",
    "            if w not in visited:\n",
    "                visited.add(w)\n",
    "                dist_vw = nx.shortest_path_length(graph,v,w) #假设存在最短路径\n",
    "                heapq.heappush(Q,(dist_vw,w))\n",
    "                S += dist_vw  # 距离 d(v,w)\n",
    "                y += graph.degree(w)\n",
    "                nd += 1\n",
    "            else:\n",
    "                LCUT = LCUT + 1/(n-1)\n",
    "\n",
    "    #最终计算\n",
    "    LCUT_final = S / (n-1)\n",
    "\n",
    "    \n",
    "    return LCUT_final\n",
    "\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath, top_k=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    data = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_edges_from(data.values.tolist())\n",
    "    graph = directed_graph.to_undirected()\n",
    "\n",
    "    print(f\"Undirected graph created with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges.\")\n",
    "    print(\"Calculating initial lower bounds using PageRank...\")\n",
    "\n",
    "    initial_lower_bounds = pagerank_lower_bound(graph)\n",
    "    \n",
    "    k_lowest_farness = heapq.nsmallest(top_k, initial_lower_bounds.items(), key=lambda item: item[1])\n",
    "    print(f\"\\n{top_k} nodes with lowest farness values:\")\n",
    "    for node, farness in k_lowest_farness:\n",
    "        print(f\"Node: {node}, Farness: {farness}\")\n",
    "    \n",
    "    Farn = initial_lower_bounds.copy()\n",
    "    Top = []\n",
    "    Q = [(Farn[node], node) for node in graph.nodes()]\n",
    "    heapq.heapify(Q)\n",
    "\n",
    "    initial_threshold = float('inf')\n",
    "\n",
    "\n",
    "    _, v = heapq.heappop(Q)\n",
    "    \n",
    "    print(f\"Processing node {v}\")\n",
    "\n",
    "    threshold = initial_threshold if len(Top) < top_k else Farn[Top[-1]]\n",
    "    refined_bound = updateBoundsBFSCut(v, graph, threshold)\n",
    "    \n",
    "    print(f\"Refined bound for node {v}: {refined_bound}\")\n",
    "\n",
    "    Farn[v] = refined_bound\n",
    "\n",
    "    while Q:\n",
    "        \n",
    "        if len(Top) < top_k:\n",
    "            Top.append(v)\n",
    "            Top.sort(key=lambda node: Farn[node])\n",
    "            print(f\"Added node {v} to Top. Current Top: {Top}\")\n",
    "        elif refined_bound < Farn[Top[-1]]:\n",
    "            Top.append(v)\n",
    "            Top.sort(key=lambda node: Farn[node])\n",
    "            Top = Top[:top_k]  # 保持Top的长度为top_k\n",
    "            print(f\"Added node {v} to Top and trimmed. Current Top: {Top}\")\n",
    "        else:\n",
    "            print(f\"Node {v} not added to Top as its bound is not better than current top\")\n",
    "\n",
    "        _, v = heapq.heappop(Q)\n",
    "    \n",
    "        print(f\"Processing node {v}\")\n",
    "\n",
    "        threshold = initial_threshold if len(Top) < top_k else Farn[Top[-1]]\n",
    "        refined_bound = updateBoundsBFSCut(v, graph, threshold)\n",
    "    \n",
    "        print(f\"Refined bound for node {v}: {refined_bound}\")\n",
    "\n",
    "        Farn[v] = refined_bound\n",
    "        \n",
    "        if len(Top) == top_k and Farn[v] >= Farn[Top[-1]]:\n",
    "            print(Farn[v])\n",
    "            print(Farn[Top[-1]])\n",
    "            print(\"Remaining nodes in Q cannot improve Top. Stopping.\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nFinal Top 10 nodes by refined lower centrality bound:\")\n",
    "    for i, node in enumerate(Top, 1):\n",
    "        print(f\"{i}. Node: {node}, Refined Lower Centrality: {Farn[node]:.10f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"com-youtube.ungraph.tsv\"  # 替换为你文件的路径\n",
    "    print(\"Creating graph...\")\n",
    "    graph_with_centrality = create_mention_graph_with_centrality(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
