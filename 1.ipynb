{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3309741-1757-4a44-bd02-1b0d5c769829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n",
      "Graph created with 94861 nodes and 155574 edges.\n",
      "Calculating centrality...\n",
      "2\n",
      "3\n",
      "\n",
      "Total time taken: 62.5932 seconds\n",
      "\n",
      "Top 10 nodes by lower centrality bound:\n",
      "Node: tolisv, Lower Centrality: 260865.0000000000\n",
      "Node: nishajl, Lower Centrality: 260865.0000000000\n",
      "Node: karkaremtg, Lower Centrality: 260865.0000000000\n",
      "Node: mrmwrites, Lower Centrality: 260865.0000000000\n",
      "Node: wanda_g, Lower Centrality: 260865.0000000000\n",
      "Node: mineralrich, Lower Centrality: 260865.0000000000\n",
      "Node: joeyawesome, Lower Centrality: 260865.0000000000\n",
      "Node: cruzado, Lower Centrality: 260865.0000000000\n",
      "Node: celestinechua, Lower Centrality: 260865.0000000000\n",
      "Node: georgia_mcbride, Lower Centrality: 260865.0000000000\n",
      "         132798127 function calls (132703265 primitive calls) in 62.655 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.091    0.091   62.649   62.649 2004492727.py:115(create_mention_graph_with_centrality)\n",
      "        1    0.037    0.037    0.069    0.069 2004492727.py:118(process_chunk)\n",
      "    94861    0.003    0.000    0.003    0.000 2004492727.py:150(<lambda>)\n",
      "        1   43.742   43.742   61.970   61.970 2004492727.py:64(neighborhood_lower_bound)\n",
      "        1    0.009    0.009    0.009    0.009 2004492727.py:72(<dictcomp>)\n",
      "        1    0.246    0.246    0.262    0.262 2004492727.py:76(<dictcomp>)\n",
      "        1    0.166    0.166    2.440    2.440 2004492727.py:8(compute_scc_bounds)\n",
      "  6115780    0.765    0.000    0.765    0.000 2004492727.py:96(<genexpr>)\n",
      " 48926240    6.241    0.000    6.241    0.000 2004492727.py:98(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 <class 'networkx.utils.decorators.argmap'> compilation 4:1(argmap_strongly_connected_components_1)\n",
      "    93116    0.012    0.000    0.042    0.000 <frozen _collections_abc>:778(__contains__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:790(items)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:812(__init__)\n",
      "   187979    0.027    0.000    0.059    0.000 <frozen _collections_abc>:859(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      711    0.000    0.000    0.002    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.006    0.006   62.655   62.655 <string>:1(<module>)\n",
      "    39940    0.007    0.000    0.032    0.000 __init__.py:208(findall)\n",
      "    39940    0.006    0.000    0.009    0.000 __init__.py:272(_compile)\n",
      "        3    0.000    0.000    0.000    0.000 backends.py:409(__call__)\n",
      "   222220    0.120    0.000    0.276    0.000 copy.py:128(deepcopy)\n",
      "   222220    0.047    0.000    0.066    0.000 copy.py:227(_deepcopy_dict)\n",
      "   222220    0.056    0.000    0.069    0.000 copy.py:243(_keep_alive)\n",
      "   279349    0.018    0.000    0.018    0.000 coreviews.py:267(__init__)\n",
      "   186232    0.045    0.000    0.350    0.000 coreviews.py:271(__len__)\n",
      "   444438    0.047    0.000    0.205    0.000 coreviews.py:272(<genexpr>)\n",
      "   279348    0.098    0.000    0.098    0.000 coreviews.py:274(__iter__)\n",
      "   666657    0.070    0.000    0.224    0.000 coreviews.py:281(<genexpr>)\n",
      "    93116    0.023    0.000    0.030    0.000 coreviews.py:283(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 coreviews.py:296(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 coreviews.py:304(__iter__)\n",
      "   186234    0.033    0.000    0.050    0.000 coreviews.py:311(<genexpr>)\n",
      "   279348    0.108    0.000    0.140    0.000 coreviews.py:313(__getitem__)\n",
      "   387309    0.087    0.000    0.154    0.000 coreviews.py:316(new_node_ok)\n",
      "   189724    0.008    0.000    0.008    0.000 coreviews.py:43(__init__)\n",
      "   189722    0.016    0.000    0.022    0.000 coreviews.py:49(__iter__)\n",
      "   189722    0.209    0.000    0.217    0.000 coreviews.py:80(__getitem__)\n",
      "       20    0.052    0.003    0.880    0.044 dag.py:166(topological_generations)\n",
      "        1    0.011    0.011    0.301    0.301 dag.py:219(<dictcomp>)\n",
      "        1    0.010    0.010    0.297    0.297 dag.py:220(<listcomp>)\n",
      "    93117    0.004    0.000    0.884    0.000 dag.py:244(topological_sort)\n",
      "        1    0.000    0.000    0.000    0.000 decorators.py:1242(inner_f)\n",
      "        1    0.000    0.000    0.000    0.000 decorators.py:86(_not_implemented_for)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:1041(degree)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:1085(in_degree)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:1132(out_degree)\n",
      "        2    0.000    0.000    0.000    0.000 digraph.py:1217(is_multigraph)\n",
      "        3    0.000    0.000    0.000    0.000 digraph.py:1221(is_directed)\n",
      "        1    0.000    0.000    0.602    0.602 digraph.py:1304(reverse)\n",
      "    93117    0.023    0.000    0.171    0.000 digraph.py:1320(<genexpr>)\n",
      "   129104    0.032    0.000    0.238    0.000 digraph.py:1321(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 digraph.py:316(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:364(adj)\n",
      "        5    0.000    0.000    0.000    0.000 digraph.py:37(__set__)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:383(succ)\n",
      "    93116    0.037    0.000    0.040    0.000 digraph.py:420(add_node)\n",
      "        1    0.075    0.075    0.257    0.257 digraph.py:469(add_nodes_from)\n",
      "        5    0.000    0.000    0.000    0.000 digraph.py:63(__set__)\n",
      "   302054    0.641    0.000    0.666    0.000 digraph.py:643(add_edge)\n",
      "        1    0.087    0.087    0.345    0.345 digraph.py:713(add_edges_from)\n",
      "   375954    0.060    0.000    0.157    0.000 digraph.py:874(successors)\n",
      "        1    0.000    0.000    0.000    0.000 digraph.py:931(edges)\n",
      "   387309    0.014    0.000    0.014    0.000 filters.py:20(no_filter)\n",
      "        1    0.005    0.005    0.011    0.011 filters.py:51(__init__)\n",
      "   946005    0.062    0.000    0.062    0.000 filters.py:54(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 function.py:156(freeze)\n",
      "        1    0.016    0.016    0.031    0.031 function.py:552(set_node_attributes)\n",
      "        1    0.000    0.000    0.041    0.041 function.py:652(get_node_attributes)\n",
      "        1    0.015    0.015    0.041    0.041 function.py:685(<dictcomp>)\n",
      "      8/7    0.000    0.000    0.000    0.000 functools.py:981(__get__)\n",
      "        1    0.000    0.000    0.011    0.011 graph.py:1763(subgraph)\n",
      "        1    0.000    0.000    0.035    0.035 graph.py:1869(size)\n",
      "    94862    0.008    0.000    0.031    0.000 graph.py:1905(<genexpr>)\n",
      "        1    0.000    0.000    0.035    0.035 graph.py:1912(number_of_edges)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:1964(nbunch_iter)\n",
      "    93117    0.007    0.000    0.007    0.000 graph.py:2010(bunch_iter)\n",
      "        2    0.000    0.000    0.000    0.000 graph.py:435(__iter__)\n",
      "    93117    0.012    0.000    0.054    0.000 graph.py:453(__contains__)\n",
      "   189722    0.022    0.000    0.240    0.000 graph.py:489(__getitem__)\n",
      "        5    0.000    0.000    0.000    0.000 graph.py:59(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 graph.py:732(nodes)\n",
      "        1    0.000    0.000    0.000    0.000 graph.py:825(number_of_nodes)\n",
      "        1    0.000    0.000    0.000    0.000 graphviews.py:135(subgraph_view)\n",
      "   258206    0.031    0.000    0.040    0.000 graphviews.py:223(reverse_edge)\n",
      "        1    0.000    0.000    0.000    0.000 interactiveshell.py:315(_modified_open)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:137(_event_pipe)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:258(schedule)\n",
      "       32    0.000    0.000    0.000    0.000 iostream.py:519(_is_master_process)\n",
      "       32    0.000    0.000    0.000    0.000 iostream.py:546(_schedule_flush)\n",
      "       32    0.000    0.000    0.000    0.000 iostream.py:624(write)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:1056(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:1088(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 reportviews.py:178(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 reportviews.py:182(__len__)\n",
      "        7    0.000    0.000    0.000    0.000 reportviews.py:185(__iter__)\n",
      "   282838    0.039    0.000    0.047    0.000 reportviews.py:188(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:205(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 reportviews.py:417(__init__)\n",
      "  8624280    2.217    0.000    3.690    0.000 reportviews.py:424(__call__)\n",
      "    94862    0.019    0.000    0.023    0.000 reportviews.py:448(__iter__)\n",
      "  8624277    1.215    0.000    1.473    0.000 reportviews.py:545(__getitem__)\n",
      "   186234    0.063    0.000    0.578    0.000 reportviews.py:575(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:760(__init__)\n",
      "   129103    0.006    0.000    0.006    0.000 reportviews.py:774(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 reportviews.py:787(__iter__)\n",
      "   129104    0.036    0.000    0.045    0.000 reportviews.py:788(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 socket.py:621(send)\n",
      "    93117    0.118    0.000    0.422    0.000 strongly_connected.py:15(strongly_connected_components)\n",
      "        1    0.019    0.019    0.230    0.230 strongly_connected.py:79(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "      711    0.001    0.000    0.001    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _csv.reader}\n",
      "        1    0.000    0.000   62.655   62.655 {built-in method builtins.exec}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "   888880    0.027    0.000    0.027    0.000 {built-in method builtins.id}\n",
      "   322811    0.012    0.000    0.012    0.000 {built-in method builtins.isinstance}\n",
      "660546/565685    0.032    0.000    0.072    0.000 {built-in method builtins.iter}\n",
      "  9262433    0.291    0.000    0.641    0.000 {built-in method builtins.len}\n",
      "   129103    0.007    0.000    0.007    0.000 {built-in method builtins.max}\n",
      "     9094    0.001    0.000    0.001    0.000 {built-in method builtins.min}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "        1    0.011    0.011    0.014    0.014 {built-in method builtins.sorted}\n",
      "  7956761    2.888    0.000   10.131    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     1745    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   139872    0.005    0.000    0.005    0.000 {method 'append' of 'list' objects}\n",
      "    93116    0.003    0.000    0.003    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    39940    0.017    0.000    0.017    0.000 {method 'findall' of 're.Pattern' objects}\n",
      " 31099012    2.004    0.000    2.004    0.000 {method 'get' of 'dict' objects}\n",
      "   315341    0.015    0.000    0.015    0.000 {method 'items' of 'dict' objects}\n",
      "    96606    0.004    0.000    0.004    0.000 {method 'pop' of 'list' objects}\n",
      "   839613    0.032    0.000    0.032    0.000 {method 'update' of 'dict' objects}\n",
      "    93116    0.009    0.000    0.009    0.000 {method 'update' of 'set' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "import cProfile\n",
    "from collections import defaultdict, deque\n",
    "import networkx as nx\n",
    "\n",
    "def compute_scc_bounds(graph):\n",
    "    \"\"\"在 SCC 图上迭代计算 alpha 和 omega 值。\"\"\"\n",
    "    if not isinstance(graph, nx.DiGraph) or not graph.nodes:\n",
    "        return None\n",
    "\n",
    "    # 1. 获取所有 SCC\n",
    "    sccs = list(nx.strongly_connected_components(graph))\n",
    "\n",
    "    # 2. 从 SCC 创建一个新图\n",
    "    scc_graph = nx.DiGraph()\n",
    "    scc_weights = {}\n",
    "    scc_node_map = {}\n",
    "\n",
    "    for i, scc in enumerate(sccs):\n",
    "        scc_node = f\"SCC_{i}\"\n",
    "        scc_graph.add_node(scc_node)\n",
    "        scc_weights[scc_node] = len(scc)\n",
    "        for node in scc:\n",
    "            scc_node_map[node] = scc_node\n",
    "\n",
    "    # 在 SCC 之间添加边\n",
    "    for u in graph.nodes:\n",
    "        for v in graph.neighbors(u):\n",
    "            if scc_node_map[u] != scc_node_map[v]:\n",
    "                scc_graph.add_edge(scc_node_map[u], scc_node_map[v])\n",
    "\n",
    "    # 3. 初始化所有 SCC 节点的 alpha 和 omega\n",
    "    scc_bounds = {}\n",
    "    for scc_node in scc_graph.nodes:\n",
    "        scc_bounds[scc_node] = (scc_weights[scc_node], scc_weights[scc_node])\n",
    "\n",
    "    # 4. 反向拓扑排序（处理循环）\n",
    "    remaining_nodes = set(scc_graph.nodes) #考虑SCC图中的所有节点进行拓扑排序\n",
    "    reverse_topological_order = []\n",
    "    if len(remaining_nodes) > 0:\n",
    "        try:\n",
    "            reverse_topological_order = list(nx.topological_sort(scc_graph.reverse().subgraph(remaining_nodes)))\n",
    "        except nx.NetworkXUnfeasible:\n",
    "            print(\"Warning: SCC 图中检测到循环。使用启发式排序。\")\n",
    "            reverse_topological_order = sorted(remaining_nodes, key=lambda node: scc_graph.degree(node), reverse=True)\n",
    "\n",
    "    # 5. 迭代并更新 alpha 和 omega\n",
    "    for scc_node in reversed(reverse_topological_order): #反向迭代\n",
    "        for neighbor in scc_graph.neighbors(scc_node):\n",
    "            scc_bounds[scc_node] = (max(scc_bounds[scc_node][0], scc_bounds[neighbor][0]),\n",
    "                                    scc_bounds[scc_node][1] + scc_bounds[neighbor][1])\n",
    "\n",
    "    # 6. 将边界分配给原始节点\n",
    "    node_bounds = {}\n",
    "    for node in graph.nodes:\n",
    "        scc_node = scc_node_map[node]\n",
    "        node_bounds[node] = scc_bounds[scc_node]\n",
    "\n",
    "    return node_bounds\n",
    "\n",
    "\n",
    "def neighborhood_lower_bound(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    n = len(nodes)\n",
    "    lower_bounds = {}\n",
    "    scc_bounds = compute_scc_bounds(graph)\n",
    "    if scc_bounds is None:\n",
    "        print(\"Error computing SCC bounds. Returning empty dictionary.\")\n",
    "        return {}\n",
    "    reachable_nodes_dict = {node: bounds[0] for node, bounds in scc_bounds.items()}\n",
    "    k = 2\n",
    "    max_iterations = 10\n",
    "    print('2')\n",
    "    neighbors_dict = {node: list(graph.neighbors(node)) for node in nodes}\n",
    "    print('3')\n",
    "    while k <= max_iterations:\n",
    "        Y = {}\n",
    "        S_un = {}  # Restore S_un to a dictionary\n",
    "        nVisited = {}\n",
    "        finished = {}\n",
    "        for s in nodes:\n",
    "            degree_s = graph.out_degree(s)  # Changed to out-degree\n",
    "            Y[(k - 1, s)] = degree_s\n",
    "            S_un[(k - 1, s)] = degree_s\n",
    "            nVisited[s] = degree_s + 1\n",
    "            finished[s] = False\n",
    "        nFinished = 0\n",
    "        while nFinished < n:\n",
    "            for s in nodes:\n",
    "                if finished[s]:\n",
    "                    continue\n",
    "                r_v = reachable_nodes_dict[s]\n",
    "                if k == 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in neighbors_dict[s]) - graph.out_degree(s)  # Changed to out-degree\n",
    "                elif k > 2:\n",
    "                    Y[(k, s)] = sum(Y[(k - 1, w)] for w in neighbors_dict[s]) - Y.get((k - 2, s), 0) * (\n",
    "                            graph.out_degree(s) - 1)  # Changed to out-degree\n",
    "                else:\n",
    "                    Y[(k, s)] = 0\n",
    "                nVisited[s] += Y.get((k - 1, s), 0)\n",
    "                if nVisited[s] < r_v:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * Y.get((k - 1, s), 0)\n",
    "                else:\n",
    "                    S_un[(k, s)] = S_un.get((k - 1, s), 0) + k * (r_v - (nVisited[s] - Y.get((k - 1, s), 0)))\n",
    "                    nFinished += 1\n",
    "                    finished[s] = True\n",
    "        k += 1\n",
    "    for v in nodes:\n",
    "        r_v = reachable_nodes_dict[v]\n",
    "        lower_bounds[v] = (n - 1) * S_un.get((k - 1, v), 0) / ((r_v - 1) ** 2) if r_v > 1 else 0\n",
    "    return lower_bounds\n",
    "\n",
    "def create_mention_graph_with_centrality(filepath):\n",
    "    start_time = time.time()\n",
    "    edge_weights = defaultdict(int)\n",
    "    def process_chunk(chunk):\n",
    "        for row in chunk:\n",
    "            try:\n",
    "                timestamp, user, tweet_text = row\n",
    "                mentions = re.findall(r'@([a-zA-Z0-9_]+)', tweet_text)\n",
    "                for mention in mentions:\n",
    "                    edge_weights[(user, mention)] += 1\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Error processing row: {row}. Skipping. Error: {e}\")\n",
    "    chunk_size = 100000\n",
    "    current_chunk = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            current_chunk.append(row)\n",
    "            if len(current_chunk) == chunk_size:\n",
    "                process_chunk(current_chunk)\n",
    "                current_chunk = []\n",
    "    if current_chunk:\n",
    "        process_chunk(current_chunk)\n",
    "    G = nx.DiGraph()\n",
    "    for (u, v), weight in edge_weights.items():\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "    print(f\"Graph created with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    print(\"Calculating centrality...\")\n",
    "    lower_bounds = neighborhood_lower_bound(G)\n",
    "    nx.set_node_attributes(G, lower_bounds, 'lower_centrality')\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"\\nTotal time taken: {total_time:.4f} seconds\")\n",
    "    sorted_centralities = sorted(\n",
    "        nx.get_node_attributes(G, 'lower_centrality').items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    print(\"\\nTop 10 nodes by lower centrality bound:\")\n",
    "    for node, centrality in sorted_centralities[:10]:\n",
    "        print(f\"Node: {node}, Lower Centrality: {centrality:.10f}\")\n",
    "    return G\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"twitter-small.tsv\"  # Replace with your file path\n",
    "    print(\"Creating graph...\")\n",
    "    cProfile.run('create_mention_graph_with_centrality(\"twitter-small.tsv\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296b793-18bd-42bd-9426-695acf976ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
